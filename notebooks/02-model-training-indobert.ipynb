{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b26fd8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, EarlyStoppingCallback\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "705418c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../dataset/processed/train.csv')\n",
    "val_df = pd.read_csv('../dataset/processed/validation.csv')\n",
    "test_df = pd.read_csv('../dataset/processed/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29774487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (3500, 2)\n",
      "Validation shape: (750, 2)\n",
      "Test shape: (750, 2)\n",
      "\n",
      "Train DataFrame head:\n",
      "                                        cleaned_text  label\n",
      "0  warga kp bayam itu yang lahannya dipakai buat ...      5\n",
      "1  team pesona bobby kertanegara mulai turun tang...      5\n",
      "2  kapolri jenderal listyo sigit prabowo menghadi...      6\n",
      "3  ini lah hasil dari kinerja pak prabowo selama ...      5\n",
      "4  puluhan ribu masyarakat menyambut kedatangan a...      5\n"
     ]
    }
   ],
   "source": [
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Validation shape:\", val_df.shape)\n",
    "print(\"Test shape:\", test_df.shape)\n",
    "print(\"\\nTrain DataFrame head:\")\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6959e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-large-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"indobenchmark/indobert-large-p2\"\n",
    "num_labels = 8\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf6c3c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "645b56565f404af08b2e3da6e462ac75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3494 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94b9aeabed8d40ac922834b8dd433d7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/749 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56bc455d426d4138b76c3cf393e679a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/748 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert pandas DataFrames to Hugging Face Datasets and tokenize\n",
    "\n",
    "# Drop rows with missing cleaned_text\n",
    "train_df_clean = train_df.dropna(subset=['cleaned_text'])\n",
    "val_df_clean = val_df.dropna(subset=['cleaned_text'])\n",
    "test_df_clean = test_df.dropna(subset=['cleaned_text'])\n",
    "\n",
    "def tokenize_function(batch):\n",
    "    return tokenizer(batch['cleaned_text'], padding='max_length', truncation=True, max_length=256)\n",
    "\n",
    "# Convert to Hugging Face Dataset objects\n",
    "train_dataset = Dataset.from_pandas(train_df_clean[['cleaned_text', 'label']])\n",
    "val_dataset = Dataset.from_pandas(val_df_clean[['cleaned_text', 'label']])\n",
    "test_dataset = Dataset.from_pandas(test_df_clean[['cleaned_text', 'label']])\n",
    "\n",
    "# Tokenize datasets\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Set format for PyTorch\n",
    "columns = ['input_ids', 'attention_mask', 'label']\n",
    "train_dataset.set_format(type='torch', columns=columns)\n",
    "val_dataset.set_format(type='torch', columns=columns)\n",
    "test_dataset.set_format(type='torch', columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0829dc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='weighted')\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "# Improved training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../results_indobert\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=500,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=100,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    save_total_limit=3,\n",
    "    report_to=None,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f04d4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc013060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation and test sets\n",
    "val_results = trainer.evaluate(eval_dataset=val_dataset)\n",
    "test_results = trainer.evaluate(eval_dataset=test_dataset)\n",
    "\n",
    "print(\"Validation Results:\", val_results)\n",
    "print(\"Test Results:\", test_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "indonesian-tweet-classification-indobert-3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
